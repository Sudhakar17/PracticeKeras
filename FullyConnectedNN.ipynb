{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dense - fully connected networks\n",
    "Dropout - used in CNN\n",
    "Activation - ReLU, Sigmoid, tanh\n",
    "Sequential - Linear stack of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PolyCollection at 0x2ac9c610e80>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ac9bb17c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.pcolor(x_train[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128,input_shape = (784,)))\n",
    "model.add(Activation('sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Wall time: 68.6 ms\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "#To delete a previous layers in keras\n",
    "#model.layers = model.layers[:-1]\n",
    "model.summary()\n",
    "%time model.compile(loss='categorical_crossentropy',optimizer=SGD(),metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 1s - loss: 2.0138 - acc: 0.5207 - val_loss: 1.7259 - val_acc: 0.7000\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 1s - loss: 1.5148 - acc: 0.7407 - val_loss: 1.2956 - val_acc: 0.7882\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 1s - loss: 1.1651 - acc: 0.7949 - val_loss: 1.0158 - val_acc: 0.8202\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 1s - loss: 0.9440 - acc: 0.8217 - val_loss: 0.8424 - val_acc: 0.8399\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 1s - loss: 0.8045 - acc: 0.8363 - val_loss: 0.7305 - val_acc: 0.8491\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 1s - loss: 0.7113 - acc: 0.8468 - val_loss: 0.6535 - val_acc: 0.8573\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 1s - loss: 0.6454 - acc: 0.8553 - val_loss: 0.5973 - val_acc: 0.8650\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 1s - loss: 0.5963 - acc: 0.8620 - val_loss: 0.5548 - val_acc: 0.8705\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 1s - loss: 0.5584 - acc: 0.8673 - val_loss: 0.5213 - val_acc: 0.8764\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 1s - loss: 0.5282 - acc: 0.8717 - val_loss: 0.4946 - val_acc: 0.8796\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.03224222336\n",
      "Test accuracy: 0.8159\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using CPU: More number of epochs(iterations) can increase a test accuracy. Due to time and resource constraint, I assigned epochs = 3 . Accuracy was  81.59\n",
    "\n",
    "Using GPU: Accuracy is 87.96"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
